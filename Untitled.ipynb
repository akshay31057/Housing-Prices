{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'train.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1fa77d369aca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0miris\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m### Separating hours,minutes,dates,years for dateBuilt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hp-\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hp-\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hp-\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hp-\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hp-\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'train.csv' does not exist"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import datetime\n",
    "iris=pd.read_csv(\"train.csv\")\n",
    "df=pd.DataFrame(iris)\n",
    "### Separating hours,minutes,dates,years for dateBuilt\n",
    "df['dateBuilt']=df['dateBuilt'].apply(lambda x:x.upper())\n",
    "for i in range(16500):\n",
    "    string=str(df.iloc[i,3])\n",
    "    index=re.search(r'[0-9]+/[0-9]+(/.*)',string).start(1);\n",
    "    li=list(string)\n",
    "\n",
    "    li[index+2]='9'\n",
    "    stre = ''.join(str(e) for e in li)\n",
    "    df.iloc[i,3]=stre\n",
    "\n",
    "df['dateBuilt']=pd.to_datetime(df.dateBuilt)\n",
    "df['HOUR'] = df['dateBuilt'].dt.hour\n",
    "df['MONTH'] = df['dateBuilt'].dt.month\n",
    "df['DATE'] = df['dateBuilt'].dt.day\n",
    "df['YEAR'] = df['dateBuilt'].dt.year\n",
    "###\n",
    "### Separating hours,minutes,dates,years for datePriced\n",
    "\n",
    "df['datePriced']=df['datePriced'].apply(lambda x:x.upper())\n",
    "for i in range(16500):\n",
    "    string=str(df.iloc[i,4])\n",
    "    index=re.search(r'[0-9]+/[0-9]+(/.*)',string).start(1);\n",
    "    li=list(string)\n",
    "\n",
    "    li[index+2]='9'\n",
    "    stre = ''.join(str(e) for e in li)\n",
    "    df.iloc[i,4]=stre\n",
    "\n",
    "df['datePriced']=pd.to_datetime(df.datePriced)\n",
    "df['HOURPriced'] = df['datePriced'].dt.hour\n",
    "df['MONTHPriced'] = df['datePriced'].dt.month\n",
    "df['DATEPriced'] = df['datePriced'].dt.day\n",
    "df['YEARPriced'] = df['datePriced'].dt.year\n",
    "###\n",
    "\n",
    "### Enumerating builders for analysis and training \n",
    "target_map = {'Bob':0, 'Bright_Brothers':1,'Masters_of_Stones':2,'Not_Known':3,'The_Greens':4,'The_Kings':5,'The_Lannisters':5,'The_Ollivers':6,'The_Overlords':7,'The_Starks':8,'Wood_Priests':9 }\n",
    "# Use the pandas apply method to numerically encode our attrition target variable\n",
    "df['builder'] = df['builder'].apply(lambda x: target_map[x])\n",
    "###\n",
    "\n",
    "### Filling the training data (NaN values)\n",
    "df['knightDistance']=df['knightDistance'].fillna(34.365941)\n",
    "df['capitalDistance']=df['capitalDistance'].fillna(34.365941)\n",
    "df['marketDistance']=df['marketDistance'].fillna(48.715817)\n",
    "df['towerDistance']=df['towerDistance'].fillna(101.110421)\n",
    "df['dockDistance']=df['dockDistance'].fillna(46.305520)\n",
    "df['location']=df['location'].fillna('the mountains')\n",
    "df['farmland']=df['farmland'].fillna(1)\n",
    "df['diningRooms']=df['diningRooms'].fillna(3)\n",
    "df['bathRooms']=df['bathRooms'].fillna(2)\n",
    "df['bedRooms']=df['bedRooms'].fillna(3)\n",
    "df['holyTree']=df['holyTree'].fillna(3)\n",
    "df['cursed']=df['cursed'].fillna(0)\n",
    "df['renovated']=df['renovated'].fillna(0)\n",
    "df['garden']=df['garden'].fillna(0)\n",
    "df=df.assign(prod=(df['bedRooms']+df['bathRooms']+df['diningRooms'])//3.0)\n",
    "df=df.assign(proddis=(df['dockDistance']*df['marketDistance']*df['towerDistance']*df['riverDistance'])**(1/3))\n",
    "df=df.assign(proddis2=np.sqrt(df['capitalDistance']*df['knightDistance']))\n",
    "###\n",
    "\n",
    "### Enumerating location for analysis and training \n",
    "target_map={'the mountains':0,\"king's landing\": 1,\"servant's premises\":2,\"cursed land\":3}\n",
    "df['location']=df['location'].apply(lambda x: target_map[x])\n",
    "###\n",
    "\n",
    "k=4\n",
    "tr=df\n",
    "tE=pd.read_csv('test.csv')\n",
    "te=pd.DataFrame(tE)\n",
    "######\n",
    "\n",
    "te['datePriced']=te['datePriced'].apply(lambda x:x.upper())\n",
    "for i in range(3500):\n",
    "    string=str(te.iloc[i,4])\n",
    "    index=re.search(r'[0-9]+/[0-9]+(/.*)',string).start(1);\n",
    "    li=list(string)\n",
    "\n",
    "    li[index+2]='9'\n",
    "    stre = ''.join(str(e) for e in li)\n",
    "    te.iloc[i,4]=stre\n",
    "\n",
    "te['datePriced']=pd.to_datetime(te.datePriced)\n",
    "te['HOURPriced'] = te['datePriced'].dt.hour\n",
    "te['MONTHPriced'] = te['datePriced'].dt.month\n",
    "te['DATEPriced'] = te['datePriced'].dt.day\n",
    "te['YEARPriced'] = te['datePriced'].dt.year\n",
    "\n",
    "te['dateBuilt']=te['dateBuilt'].apply(lambda x:x.upper())\n",
    "for i in range(3500):\n",
    "    string=str(te.iloc[i,3])\n",
    "    index=re.search(r'[0-9]+/[0-9]+(/.*)',string).start(1);\n",
    "    li=list(string)\n",
    "\n",
    "    li[index+2]='9'\n",
    "    stre = ''.join(str(e) for e in li)\n",
    "    te.iloc[i,3]=stre\n",
    "\n",
    "te['dateBuilt']=pd.to_datetime(te.dateBuilt)\n",
    "te['HOUR'] = te['dateBuilt'].dt.hour\n",
    "te['MONTH'] = te['dateBuilt'].dt.month\n",
    "te['DATE'] = te['dateBuilt'].dt.day\n",
    "te['YEAR'] = te['dateBuilt'].dt.year\n",
    "\n",
    "\n",
    "\n",
    "### Doing the same for the test data \n",
    "te['knightDistance']=te['knightDistance'].fillna(34.365941)\n",
    "te['capitalDistance']=te['capitalDistance'].fillna(34.365941)\n",
    "te['marketDistance']=te['marketDistance'].fillna(48.715817)\n",
    "te['towerDistance']=te['towerDistance'].fillna(101.110421)\n",
    "te['dockDistance']=te['dockDistance'].fillna(46.305520)\n",
    "te['location']=te['location'].fillna('the mountains')\n",
    "te['farmland']=te['farmland'].fillna(1)\n",
    "te['diningRooms']=te['diningRooms'].fillna(3)\n",
    "te['bathRooms']=te['bathRooms'].fillna(2)\n",
    "te['bedRooms']=te['bedRooms'].fillna(3)\n",
    "te['holyTree']=te['holyTree'].fillna(3)\n",
    "te['cursed']=te['cursed'].fillna(0)\n",
    "te['renovated']=te['renovated'].fillna(0)\n",
    "te['garden']=te['garden'].fillna(0)\n",
    "te=te.assign(prod=(te['bedRooms']+te['bathRooms']+te['diningRooms'])//3.0)\n",
    "\n",
    "target_map={'the mountains':0,\"king's landing\": 1,\"servant's premises\":2,\"cursed land\":3}\n",
    "te['location']=te['location'].apply(lambda x: target_map[x])\n",
    "target_map = {'Bob':0, 'Bright_Brothers':1,'Masters_of_Stones':2,'Not_Known':3,'The_Greens':4,'The_Kings':5,'The_Lannisters':5,'The_Ollivers':6,'The_Overlords':7,'The_Starks':8,'Wood_Priests':9 }\n",
    "# Use the pandas apply method to numerically encode our attrition target variable\n",
    "\n",
    "te['builder'] = te['builder'].apply(lambda x: target_map[x])\n",
    "### \n",
    "\n",
    "model=linear_model.LinearRegression(normalize=True)###using linear regression\n",
    "tr_X = tr[[ 'builder','dockDistance',  'marketDistance', 'towerDistance', 'riverDistance','capitalDistance','diningRooms','bedRooms',\n",
    " 'bathRooms' ,'kingVisit', 'cursed', 'blessings', 'farmland', 'location', 'holyTree','YEAR','YEARPriced','MONTH','MONTHPriced','HOUR','prod']]# taking the training data features\n",
    "\n",
    "tr_y = tr[['goldenGrains']]# output of our training data\n",
    "te_X = te[[ 'builder','dockDistance',  'marketDistance', 'towerDistance', 'riverDistance','capitalDistance','diningRooms','bedRooms',\n",
    " 'bathRooms' ,'kingVisit', 'cursed', 'blessings', 'farmland', 'location', 'holyTree','YEAR','YEARPriced','MONTH','MONTHPriced','HOUR','prod']]# taking the training data features\n",
    "\n",
    "\n",
    "model.fit(tr_X,tr_y)\n",
    "prediction = model.predict(te_X)\n",
    "prediction\n",
    "pred=pd.DataFrame(prediction)\n",
    "pred.insert(loc=0,column='houseID',value=te['houseID'])\n",
    "pred.to_csv(path_or_buf='answer4final.csv',header=['House ID','Golden Grains'],mode='w',index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
